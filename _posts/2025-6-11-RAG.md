---
layout: post
title: Retrieval-Augmente Generation (Draft)
thumbnail: "/images/CTC/thumbnail.mp4"
---

***
You must have heard about this term booming all across the feilds of AI.

Well does the hype for it lives upto the expectations of its impact? Yess!! ofcourse, it does, and we will deep dive into its core functionality by familirizing with each of its componenets piece by piece.

Before that we will look into how an llm generates an output without RAG to understand the need for it.

![_config.yml]({{ site.baseurl }}/images/RAG/vanilla_LLM.png)

Meanwhile on June 14, 2025, South Africa just chased down 282 at Lordâ€™s to get their first icc cup ever.

You can see the problem here, without RAG, the LLM is not able to give the information that is up to date, to fix these sort of issues we use RAG.

We can categorize this RAG into 3 types:

i. Naive RAG

ii. Advanced RAG

iii. Modular RAG

Let us get into the Naive RAG, it follows a traditional process that includes indexing, retrieval and generation

![_config.yml]({{ site.baseurl }}/images/RAG/Naive_RAG.png)

we will dive deep into each of these components.

![_config.yml]({{ site.baseurl }}/images/RAG/indexing_naive_rag.png)

The **source**(documents) can be of any text type (optimizingly using these sources will be discussed later), is then passed to a stage **formatting**, here texts from different sources are combined, then cleaned and are normalized so that all the text is converted to uniform plain text format, this step is crucial because it does help to remove any disrepancy in wordings (CAT, Cats, cat are considered same), this formatted text is then passed to **chunking** where the text is split into fixed sizes, this chunks are chunks then passed into an embedidng model (sounds fancy but it is just a model which converts text to numbers so that the machines can interpret it more easily), now we have **vector representations** of the chunks, these vectors are stored in a vector database (optimizing this database for faster processing is discussed later).





