---
layout: post
title: Connectionist Temporal Classification
---




***

Dare I say, ctc is as crucial as transformers in language models.

Ctc can be used for cursive handwriting, sequence based problems, digital signal processing especially in automatic speech recognition(ASR).

So, what is the base of ctc?

They are Recurrent neural network (RNN)

We will try looking for __ASR__, that is speech to text and what is speech made of? 

Yes audio...

Audio can be in form of wave or digital signal

This raw audio is directly given as an input to the rnn.


But it would be impractical for rnn to take whole audio at once, so the audio is split into frames 

![_config.yml]({{ site.baseurl }}/images/CTC/waves_split_to_frames.gif)


>__Did you know__: although digital signals look continuous, they are not! They are infact discrete in both time and amplitude


>![_config.yml]({{ site.baseurl }}/images/CTC/discrete_signals.gif)

These frames are given as inputs to the rnn, one by one...

![_config.yml]({{ site.baseurl }}/images/CTC/frames_to_rnn.gif)

What are these outputs (y1,y2,y3)..?

These outputs are classified labels...

Now what are this?

Let us take an example,
Sentence = **_‘I am Batman’_**

Classification labels are the unique characters either in a sentence or a corpus,so for the senenece above, the labels are __I,a,m,B,t,n__

Let us see what are the classification labels from y1

![_config.yml]({{ site.baseurl }}/images/CTC/random_outputs_from_rnn.gif)

The label values are random consisting both positive and negative values.

Now, what is the problem with the above values…?
There is no parameter or heuristic to compare the probable output out of all the labels from y1...

There is a saviour for us in terms of **_SOFTMAX_**

![_config.yml]({{ site.baseurl }}/images/CTC/softmax.png)

It is just a function that converts all labelled values in the range 0 to 1.

How does this help now?In a way of fact, they can be used as probability of occurrence of a character. 

![_config.yml]({{ site.baseurl }}/images/CTC/rnn_outputs_after_softmax.png)

Similarly, as for y1 in t1, every output from rnn is stored from various times in some backend.

![_config.yml]({{ site.baseurl }}/images/CTC/all_rnn_outputs.png)

![_config.yml]({{ site.baseurl }}/images/CTC/probability_legend.png)

Okay, now we have got the arsenals in our hand, the nodes(probabilities) for all labels in different time stamps.

What is our goal? 

Align the sounds in text format, for simplicity we are using characters which are needed to be aligned.Though it is as easy as it sounds, there are many obstacles to reach the fortress.
Let us face the obstacles one by one.

Firstly, let us just arrange the nodes in an order and see how it looks, for simplicity we will try to align just for **_batman_**

![_config.yml]({{ site.baseurl }}/images/CTC/node_map.png)

We know that, the sound of /b/ in batman or rather any other character can occupy more than one time stamp, as a single time stamp can be as small as 10ms, and people speak either slow or fast. Thus, the characters may repeat.

ok, now say we select the most probable label at each time stamp, and the output may look like this,

![_config.yml]({{ site.baseurl }}/images/CTC/node_map_2.png)

It returns a text of **bbatmmaan**!

How do we deal with the repeated characters? Simple, just merge them into one, 

![_config.yml]({{ site.baseurl }}/images/CTC/merge_duplicates.png)

As we can see from the image, repeated characters are collapsed into one.We got the perfect text for what we have spoken, everything is great.

But life is not that simple, there are two problems in the fixture, let us figure out what they are,look the arrow directions from start to end,

![_config.yml]({{ site.baseurl }}/images/CTC/no_monotonicity_1.png)

Did you find out the problem? Let me show you another example for target sequence of **_I am batman_**, focus on the edges this time…

![_config.yml]({{ site.baseurl }}/images/CTC/no_monotonicity_2.png)

The problem is in the path or alignment that it follows is it is **not monotonic** and it is **ambiguous**.And if the target sequence is long, it becomes a mess which also affects in computation, what should we do?

Given a target sequence, the nodes should be **_‘constrained’_**, that is the order of the classification labels should be sorted in order of target sequence along with the repeated characters in the target sequence.

See the image below of how constraining the nodes will result us a monotonic order.

![_config.yml]({{ site.baseurl }}/images/CTC/monotonicity.png)

observe the edges...

![_config.yml]({{ site.baseurl }}/images/CTC/monotonicity_arrow.png)

Every time the alignment is starting from **top left** and ends at **bottom right**. This is important for future algorithm that we are going to discuss later.


One problem is sorted, what about the other problem, let me give you an example:

For the target sequence **‘pool’**, what should my alignment be? How can I tackle the repeated characters without merging them.

![_config.yml]({{ site.baseurl }}/images/CTC/duplicate_prob.png)

There is good solution for it, use a blank symbol, generally represented with ‘ε’. How does it affect? 

![_config.yml]({{ site.baseurl }}/images/CTC/duplicate_solved.png)

It is working great, let us see it with the alignment too,

![_config.yml]({{ site.baseurl }}/images/CTC/node_with_epsilon.png)

Output text = pϵooϵooϵl --> pool

Nice! We have bypassed with repeated character issue and as well as the lack of monotonicity. 

Now, let us find out how ctc model is trained, There are two issues with it again…

Say, only output sequence is provided for training data, no timing information for each label is provided, in this scenario how can we know when to output the symbols, and if some symbols are returned in output how do we know that they are real? 

We will get into this later, but suppose we got to know what are the real outputs for a sequence at every given time step, how do we train that model, specifically how is backpropagation done?

![_config.yml]({{ site.baseurl }}/images/CTC/divergence.png)

For CTC, the divergence is calculated between the ground truth labels and output generated by the model(prediction).



<video muted autoplay controls>
    <source src="/images/CTC/viterbi_algo.mp4" type="video/mp4">
</video



