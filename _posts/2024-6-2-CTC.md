---
layout: post
title: Connectionist Temporal Classification
---




***

Dare I say, ctc is as crucial as transformers in language models.

Ctc can be used for cursive handwriting, sequence based problems, digital signal processing especially in automatic speech recognition(ASR).

So, what is the base of ctc?

They are Recurrent neural network (RNN)

We will try looking for __ASR__, that is speech to text and what is speech made of? 

Yes audio...

Audio can be in form of wave or digital signal

This raw audio is directly given as an input to the rnn.


But it would be impractical for rnn to take whole audio at once, so the audio is split into frames 

<video muted autoplay controls style="max-width: 100%">
    <source src="/images/CTC/frames_in_ctc.mp4.mp4" type="video/mp4">
</video>



>__Did you know__: although digital signals look continuous, they are not! They are infact discrete in both time and amplitude


>![_config.yml]({{ site.baseurl }}/images/CTC/discrete_signals.gif)

These frames are given as inputs to the rnn, one by one...

<video muted autoplay controls style="max-width: 100%">
    <source src="/images/CTC/frames_to_rnn.mp4" type="video/mp4">
</video>


What are these outputs (y1,y2,y3)..?

These outputs are classified labels...

Now what are this?

Let us take an example,
Sentence = **_‘I am Batman’_**

Classification labels are the unique characters either in a sentence or a corpus,so for the senenece above, the labels are __I,a,m,B,t,n__

Let us see what are the classification labels from y1

<video muted autoplay='1' controls style="max-width: 100%">
    <source src="/images/CTC/random_outputs_from_rnn.mp4" type="video/mp4">
</video>


The label values are random consisting both positive and negative values.

Now, what is the problem with the above values…?
There is no parameter or heuristic to compare the probable output out of all the labels from y1...

There is a saviour for us in terms of **_SOFTMAX_**

![_config.yml]({{ site.baseurl }}/images/CTC/softmax.png)

It is just a function that converts all labelled values in the range 0 to 1.

How does this help now?In a way of fact, they can be used as probability of occurrence of a character. 

![_config.yml]({{ site.baseurl }}/images/CTC/rnn_outputs_after_softmax.png)

Similarly, as for y1 in t1, every output from rnn is stored from various times in some backend.

![_config.yml]({{ site.baseurl }}/images/CTC/all_rnn_outputs.png)

![_config.yml]({{ site.baseurl }}/images/CTC/probability_legend.png)

Okay, now we have got the arsenals in our hand, the nodes(probabilities) for all labels in different time stamps.

What is our goal? 

Align the sounds in text format, for simplicity we are using characters which are needed to be aligned.Though it is as easy as it sounds, there are many obstacles to reach the fortress.
Let us face the obstacles one by one.

Firstly, let us just arrange the nodes in an order and see how it looks, for simplicity we will try to align just for **_batman_**

![_config.yml]({{ site.baseurl }}/images/CTC/node_map.png)

We know that, the sound of /b/ in batman or rather any other character can occupy more than one time stamp, as a single time stamp can be as small as 10ms, and people speak either slow or fast. Thus, the characters may repeat.

ok, now say we select the most probable label at each time stamp, and the output may look like this,

![_config.yml]({{ site.baseurl }}/images/CTC/node_map_2.png)

It returns a text of **bbatmmaan**!

How do we deal with the repeated characters? Simple, just merge them into one, 

![_config.yml]({{ site.baseurl }}/images/CTC/merge_duplicates.png)

As we can see from the image, repeated characters are collapsed into one.We got the perfect text for what we have spoken, everything is great.

But life is not that simple, there are two problems in the fixture, let us figure out what they are,look the arrow directions from start to end,

![_config.yml]({{ site.baseurl }}/images/CTC/no_monotonicity_1.png)

Did you find out the problem? Let me show you another example for target sequence of **_I am batman_**, focus on the edges this time…

![_config.yml]({{ site.baseurl }}/images/CTC/no_monotonicity_2.png)

The problem is in the path or alignment that it follows is it is **not monotonic** and it is **ambiguous**.And if the target sequence is long, it becomes a mess which also affects in computation, what should we do?

Given a target sequence, the nodes should be **_‘constrained’_**, that is the order of the classification labels should be sorted in order of target sequence along with the repeated characters in the target sequence.

See the image below of how constraining the nodes will result us a monotonic order.

![_config.yml]({{ site.baseurl }}/images/CTC/monotonicity.png)

observe the edges...

![_config.yml]({{ site.baseurl }}/images/CTC/monotonicity_arrow.png)

Every time the alignment is starting from **top left** and ends at **bottom right**. This is important for future algorithm that we are going to discuss later.


One problem is sorted, what about the other problem, let me give you an example:

For the target sequence **‘pool’**, what should my alignment be? How can I tackle the repeated characters without merging them.

![_config.yml]({{ site.baseurl }}/images/CTC/duplicate_prob.png)

There is good solution for it, use a blank symbol, generally represented with ‘ε’. How does it affect? 

![_config.yml]({{ site.baseurl }}/images/CTC/duplicate_solved.png)

It is working great, let us see it with the alignment too,

![_config.yml]({{ site.baseurl }}/images/CTC/node_with_epsilon.png)

Output text = pϵooϵooϵl --> pool

Nice! We have bypassed with repeated character issue and as well as the lack of monotonicity. 

Now, let us find out how ctc model is trained, There are two issues with it again…

Say, only output sequence is provided for training data, no timing information for each label is provided, in this scenario how can we know when to output the symbols, and if some symbols are returned in output how do we know that they are real? 

We will get into this later, but suppose we got to know what are the real outputs for a sequence at every given time step, how do we train that model, specifically how is backpropagation done?

![_config.yml]({{ site.baseurl }}/images/CTC/divergence.png)

For CTC, the divergence is calculated between the ground truth labels and output generated by the model(prediction).

![_config.yml]({{ site.baseurl }}/images/CTC/divergence_2.png)

Xent -> cross entropy loss function

Generally, a loss function is something that tells the difference between wrong and right label. It doesn’t specifically give where the mistakes are, but it tells how closer or farther your predicted labels compared to real labels.


>**_Cross entropy_**:
>It can also be called as logarithmic loss. It measures the performance of classification model (predicted characters in our case). The output of a cross entropy is always between 0 and 1, The lesser the good.

The cross entropy increases if the difference between the predicted and actual probability is more.

the total divergence can now be calculated by adding all cross entropies loss from every time stamp.

![_config.yml]({{ site.baseurl }}/images/CTC/divergence_3.png)

Say, if the model didn’t output the sequence accurately, we have to change the weights in the rnn. We use a term ‘gradient’ which is the amount of change (addition or subtraction) to modify original weights. At every time stamp t, corresponding divergence value is used as a gradient to update their weights.

The total is calculated from every time stamp’s divergence, to the see the model performance.

![_config.yml]({{ site.baseurl }}/images/CTC/divergence_4.png)

In the above formula I just used the cross-entropy function to use in divergence.

For gradient we differentiate the divergence for every time step t, so except the t<span style="vertical-align: super; font-size: medium;">th</span> term, every other time step’s gradient will be zero.

![_config.yml]({{ site.baseurl }}/images/CTC/divergence_gradient.png)

Cool, we know how the backpropagation is done for ctc using divergence as a gradient.

Now we will be going into the heart of ctc, how can we handle alignments if we only know the output sequence with no timing information provided. How can the model accurately align with the output sequence?

Well, there are three methods
1.	Randomly guess the alignment with some heuristic
2.	Viterbi algorithm
3.	Backward forward algorithm

But before that let me be clear with two terms
- **Monotonicity**:

Nothing but, something that is going in a single direction. And I hope the reason for it was pretty clear from the discussion earlier.To maintain monotonicity and less ambiguity we constrain the paths to go only to its immediate next node or the one that is below it.

![_config.yml]({{ site.baseurl }}/images/CTC/constrain_rules.png)

- **Path Score**

We need to have something to compare for the best alignment among all the paths that lead destination.

![_config.yml]({{ site.baseurl }}/images/CTC/Path_score_1.png)

The path score here is the product of all the nodes that the alignment is traced with.

![_config.yml]({{ site.baseurl }}/images/CTC/path_score_1_val.png)

Similarly,

![_config.yml]({{ site.baseurl }}/images/CTC/Path_score_2.png)

![_config.yml]({{ site.baseurl }}/images/CTC/path_score_2_val.png)

simply these are the following possible paths by following monotonicity and constraining...

![_config.yml]({{ site.baseurl }}/images/CTC/possible_paths.gif)

Do you think there’s some mistake here? Can we achieve full monotonicity with every possible path from the above illustration?

Check this instance...

![_config.yml]({{ site.baseurl }}/images/CTC/possible_paths_problem.png)

Though it followed the constraints, it still did not achieve the full target text, why so?

It is because we should also constrain the nodes from backwards too, that is the path should must end at **bottom right**.

Let us now constrain that too...Initially, we block all the nodes except the end node in the last time step.

![_config.yml]({{ site.baseurl }}/images/CTC/possible_paths_solution_1.png)

You see what I did here, I similarly had blocked the nodes that are not required by iterating, for every previous time steps (only the nodes where feasible paths are possible are kept). 

![_config.yml]({{ site.baseurl }}/images/CTC/possible_paths_solution_2.png)

Let us go deeper into ctc now,

1) **Randomly estimating path:**

It Is as simple as it sounds, by following some reasonable heuristic or randomly assigning the paths is the first step.
Once a path is assigned, the model checks for the divergence and the gradient is returned back to change the original weights.

This sounds so simple, isn’t it? That’s the trap, though it may perform well only for training data, it may become less reliable for real time data (which is mostly different from trained data)

let us find an another alternative

2) **Viterbi algorithm:**

Generally, Viterbi is a dynamic programming algorithm which is used for obtaining the maximum probability in a sequence of hidden states, it does this simply by solving the sub problems (core of dynamic programming).
What are the sub problems in our quest to find the best alignment? It is to choose the highest probable path until the time step t by reviewing the previous parent nodes.

![_config.yml]({{ site.baseurl }}/images/CTC/parent_child_node.png)

In a sense, we know that the best path (maximum probability path) must be an extension to one its parent nodes.

>Some Rules:
>* If there is single incoming edge to a node just consider it as possible path
>* If there are two incoming edges competing for a single node, choose the best parent of one of them.

As usual, let us understand it more visually, 

**Initialization**

![_config.yml]({{ site.baseurl }}/images/CTC/viterbi_1.png)

Here, as constrained we initialize with top left node i.e., y<span style="vertical-align: super; font-size: medium;">b</span><span style="vertical-align: sub; font-size: medium;">0</span>.

There is no previous node, hence no parent node, BP(t=0,r=0) = None  

where t belongs to [0, T] and r belongs to [0, len(classification_labels)-1]

Best score or Bscr(0,0) =  y<span style="vertical-align: super; font-size: medium;">b</span><span style="vertical-align: sub; font-size: medium;">0</span>

Now for time stamp t1:

![_config.yml]({{ site.baseurl }}/images/CTC/viterbi_2.png)
![_config.yml]({{ site.baseurl }}/images/CTC/viterbi_init_2.png)





<video muted autoplay controls style="max-width: 100%">
    <source src="/images/CTC/viterbi_algo.mp4" type="video/mp4">
</video>


